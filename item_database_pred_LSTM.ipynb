{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries and define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully processed: data/LSTM/Items/New\\2024predictionsBaden-Württemberg.xlsx\n",
      "\n",
      "Successfully processed: data/LSTM/Items/New\\2024predictionsBayern.xlsx\n",
      "\n",
      "Successfully processed: data/LSTM/Items/New\\2024predictionsBrandenburg.xlsx\n",
      "\n",
      "Successfully processed: data/LSTM/Items/New\\2024predictionsNordrhein-Westfalen.xlsx\n",
      "\n",
      "Combined DataFrame (first few rows):\n",
      "        Date Quantity Train  Test Predict           Location\n",
      "0 2021-12-27   5445.0  <NA>  <NA>    <NA>  Baden-Württemberg\n",
      "1 2022-01-03  22495.0  <NA>  <NA>    <NA>  Baden-Württemberg\n",
      "2 2022-01-10  42228.0  <NA>  <NA>    <NA>  Baden-Württemberg\n",
      "3 2022-01-17  38619.0  <NA>  <NA>    <NA>  Baden-Württemberg\n",
      "4 2022-01-24  43536.0  <NA>  <NA>    <NA>  Baden-Württemberg\n",
      "\n",
      "Preview of table 'predictions_LSTM_Items' after saving:\n",
      "                  Date Quantity Train  Test Predict           Location\n",
      "0  2021-12-27 00:00:00   5445.0  None  None    None  Baden-Württemberg\n",
      "1  2022-01-03 00:00:00  22495.0  None  None    None  Baden-Württemberg\n",
      "2  2022-01-10 00:00:00  42228.0  None  None    None  Baden-Württemberg\n",
      "3  2022-01-17 00:00:00  38619.0  None  None    None  Baden-Württemberg\n",
      "4  2022-01-24 00:00:00  43536.0  None  None    None  Baden-Württemberg\n",
      "\n",
      "Successfully processed: data/LSTM/Items/ItemPredicting\\2024predictionsBREMSSCHEIBENBayern.xlsx\n",
      "\n",
      "Successfully processed: data/LSTM/Items/ItemPredicting\\2024predictionsÖLFILTERBrandenburg.xlsx\n",
      "\n",
      "Combined DataFrame (first few rows):\n",
      "        Date Quantity Train  Test Predict       ItemType Location\n",
      "0 2021-12-27     24.0  <NA>  <NA>    <NA>  BREMSSCHEIBEN   Bayern\n",
      "1 2022-01-03     44.0  <NA>  <NA>    <NA>  BREMSSCHEIBEN   Bayern\n",
      "2 2022-01-10     78.0  <NA>  <NA>    <NA>  BREMSSCHEIBEN   Bayern\n",
      "3 2022-01-17     99.0  <NA>  <NA>    <NA>  BREMSSCHEIBEN   Bayern\n",
      "4 2022-01-24     78.0  <NA>  <NA>    <NA>  BREMSSCHEIBEN   Bayern\n",
      "\n",
      "Preview of table 'predictions_LSTM_Items_SpecificProducts' after saving:\n",
      "                  Date Quantity Train  Test Predict       ItemType Location\n",
      "0  2021-12-27 00:00:00     24.0  None  None    None  BREMSSCHEIBEN   Bayern\n",
      "1  2022-01-03 00:00:00     44.0  None  None    None  BREMSSCHEIBEN   Bayern\n",
      "2  2022-01-10 00:00:00     78.0  None  None    None  BREMSSCHEIBEN   Bayern\n",
      "3  2022-01-17 00:00:00     99.0  None  None    None  BREMSSCHEIBEN   Bayern\n",
      "4  2022-01-24 00:00:00     78.0  None  None    None  BREMSSCHEIBEN   Bayern\n",
      "\n",
      "Clustering Data (first few rows):\n",
      "   Unnamed: 0  daysSinceLastOrder  orderCount  sumQuantity  Cluster_kmeans  \\\n",
      "0           0                 267           6          6.0               1   \n",
      "1           1                 189           2          2.0               1   \n",
      "2           2                 155           4          4.0               1   \n",
      "3           3                 105          83         85.0               1   \n",
      "4           4                  56          70        146.0               1   \n",
      "\n",
      "       ProductSubgroup   DistributionCenter  \n",
      "0  1 SÄULEN HEBEBÜHNEN    Baden-Württemberg  \n",
      "1  1 SÄULEN HEBEBÜHNEN          Brandenburg  \n",
      "2  1 SÄULEN HEBEBÜHNEN  Nordrhein-Westfalen  \n",
      "3  2 SÄULEN HEBEBÜHNEN    Baden-Württemberg  \n",
      "4  2 SÄULEN HEBEBÜHNEN               Bayern  \n",
      "\n",
      "Preview of table 'predictions_Item_Clustering' after saving:\n",
      "   Unnamed: 0  daysSinceLastOrder  orderCount  sumQuantity  Cluster_kmeans  \\\n",
      "0           0                 267           6          6.0               1   \n",
      "1           1                 189           2          2.0               1   \n",
      "2           2                 155           4          4.0               1   \n",
      "3           3                 105          83         85.0               1   \n",
      "4           4                  56          70        146.0               1   \n",
      "\n",
      "       ProductSubgroup   DistributionCenter  \n",
      "0  1 SÄULEN HEBEBÜHNEN    Baden-Württemberg  \n",
      "1  1 SÄULEN HEBEBÜHNEN          Brandenburg  \n",
      "2  1 SÄULEN HEBEBÜHNEN  Nordrhein-Westfalen  \n",
      "3  2 SÄULEN HEBEBÜHNEN    Baden-Württemberg  \n",
      "4  2 SÄULEN HEBEBÜHNEN               Bayern  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "def read_and_process_excel(file_pattern, columns_to_keep, extract_item_type=False):\n",
    "    \"\"\"Reads and processes Excel files matching a pattern, with optional extraction of item type.\"\"\"\n",
    "    xlsx_files = glob.glob(file_pattern)\n",
    "    all_data = []\n",
    "\n",
    "    for file in xlsx_files:\n",
    "        if 'predictions' in file.lower():\n",
    "            print(f\"\\nProcessing file: {file}\")\n",
    "            try:\n",
    "                df = pd.read_excel(file, engine='openpyxl')\n",
    "                print(f\"Successfully read {file}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Extract item type and location based on the file type\n",
    "            base_name = os.path.basename(file).replace('.xlsx', '').replace('predictions', '').replace('2024', '').strip()\n",
    "\n",
    "            if extract_item_type:\n",
    "                # For specific product predictions, split item type and location\n",
    "                item_type = ''.join(filter(str.isalpha, base_name.split('Bayern')[0].split('Brandenburg')[0]))  # ItemType part\n",
    "                location_name = base_name.replace(item_type, '').strip()  # Location part\n",
    "                df['ItemType'] = item_type\n",
    "                df['Location'] = location_name\n",
    "            else:\n",
    "                # For general predictions, location is the only part\n",
    "                df['Location'] = base_name\n",
    "\n",
    "            # Keep only relevant columns\n",
    "            df = df[columns_to_keep]\n",
    "\n",
    "            # Ensure numeric columns are floats and clean NaNs\n",
    "            numeric_cols = ['Quantity', 'Train', 'Test', 'Predict']\n",
    "            df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Remove Quantity values where Quantity == Predict\n",
    "            df.loc[df['Predict'] == df['Quantity'], 'Quantity'] = pd.NA\n",
    "\n",
    "            # Handle NaNs and rounding\n",
    "            df[numeric_cols] = df[numeric_cols].fillna(0).round(2).replace(0, pd.NA)\n",
    "\n",
    "            # Add to data list\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"Skipping file: {file} (does not contain 'predictions')\")\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(\"\\nCombined DataFrame (first few rows):\")\n",
    "    print(combined_df.head())\n",
    "    return combined_df\n",
    "\n",
    "def save_to_sqlite(df, db_name, table_name):\n",
    "    \"\"\"Saves the DataFrame to SQLite database.\"\"\"\n",
    "    with sqlite3.connect(db_name) as conn:\n",
    "        conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "        df_all = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 5\", conn)\n",
    "        print(f\"\\nPreview of table '{table_name}' after saving:\")\n",
    "        print(df_all)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process general predictions of Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_general = ['Date', 'Quantity', 'Train', 'Test', 'Predict', 'Location']\n",
    "combined_df_general = read_and_process_excel('data/LSTM/Items/New/*.xlsx', columns_to_keep_general, extract_item_type=False)\n",
    "\n",
    "# Save general predictions to SQLite\n",
    "save_to_sqlite(combined_df_general, 'predictions_LSTM.db', 'predictions_LSTM_Items')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process specific product subgroup predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_products = ['Date', 'Quantity', 'Train', 'Test', 'Predict', 'ItemType', 'Location']\n",
    "combined_df_products = read_and_process_excel('data/LSTM/Items/ItemPredicting/*.xlsx', columns_to_keep_products, extract_item_type=True)\n",
    "\n",
    "# Save specific product predictions to SQLite\n",
    "save_to_sqlite(combined_df_products, 'predictions_LSTM.db', 'predictions_LSTM_Items_SpecificProducts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV for item clustering and save to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file = 'data/LSTM/Items/itemClustering.csv'\n",
    "df_clustering = pd.read_csv(csv_file, sep=';', header=0)\n",
    "print(\"\\nClustering Data (first few rows):\")\n",
    "print(df_clustering.head())\n",
    "\n",
    "# Save clustering data to SQLite\n",
    "save_to_sqlite(df_clustering, 'predictions_LSTM.db', 'predictions_Item_Clustering')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
